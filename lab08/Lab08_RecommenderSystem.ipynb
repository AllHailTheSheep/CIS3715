{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# 1. load data\n",
    "user_ratings_train = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "user_ratings_test = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "movie_info =  pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "user_ratings_train = pd.merge(movie_info, user_ratings_train)\n",
    "user_ratings_test = pd.merge(movie_info, user_ratings_test)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "user_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "user_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_ratings_train = user_ratings_train.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "user_ratings_test = user_ratings_test.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "print(user_ratings_train.shape)\n",
    "print(user_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# # fill NaNs with row average\n",
    "avg = user_ratings_train.mean(axis=1)\n",
    "user_ratings_train = user_ratings_train.T.fillna(avg).T\n",
    "\n",
    "# calculate pearson similarity\n",
    "pearson_sim = user_ratings_train.T.corr(method='pearson')\n",
    "\n",
    "# create knn\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='precomputed')\n",
    "\n",
    "# get dist matrix from pearson correlation\n",
    "distance_matrix = 1 - pearson_sim.fillna(0)\n",
    "knn.fit(distance_matrix)\n",
    "\n",
    "# initialize arrays for the predicted and actual ratings\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "# for each user, for each movie, get the true rating and compare it with the top 5 similar users \n",
    "for user_id in user_ratings_test.index:\n",
    "    for movie in user_ratings_test.columns:\n",
    "        # get true rating\n",
    "        true_rating = user_ratings_test.loc[user_id, movie]\n",
    "\n",
    "        # skip if true rating isnt in the test set\n",
    "        if not np.isnan(true_rating):\n",
    "\n",
    "            # skip movie if its not rated\n",
    "            if movie not in user_ratings_train.columns:\n",
    "                continue\n",
    "            \n",
    "            # get similar users\n",
    "            sims = pearson_sim.loc[user_id]\n",
    "            # drop self similarity and any NaN then get top 5 similar users\n",
    "            top_users = sims.drop(index=user_id).dropna().sort_values(ascending=False).head(5)\n",
    "\n",
    "            # numerator and denominator for weighted average calculation\n",
    "            num = 0\n",
    "            denom = 0\n",
    "            # loop through similar users\n",
    "            for neighbor_id, sim_score in top_users.items():\n",
    "                neighbor_rating = user_ratings_train.loc[neighbor_id, movie]\n",
    "                # if similar user rated the movie use it in the prediction\n",
    "                if not np.isnan(neighbor_rating):\n",
    "                    num += sim_score * (neighbor_rating)\n",
    "                    denom += abs(sim_score)\n",
    "\n",
    "            # compute weigted average if denom is > 0\n",
    "            if denom > 0:\n",
    "                pred = num / denom\n",
    "                predictions.append(pred)\n",
    "                actual.append(true_rating)\n",
    "\n",
    "# mae\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print(\"MAE: {:.4f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8483\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# fill NaNs with row average\n",
    "avg = user_ratings_train.mean(axis=1)\n",
    "user_ratings_train = user_ratings_train.T.fillna(avg).T\n",
    "\n",
    "# calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(user_ratings_train.T)\n",
    "item_sim = pd.DataFrame(cosine_sim, index=user_ratings_train.columns, columns=user_ratings_train.columns)\n",
    "\n",
    "# create knn\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "\n",
    "# get dist matrix from cosine correlation\n",
    "distance_matrix = 1 - item_sim.fillna(0)\n",
    "knn.fit(distance_matrix.to_numpy())\n",
    "\n",
    "# initialize arrays for the predicted and actual ratings\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "# for each user, for each movie, get the true rating and compare it with the top 5 similar print(movie in item_sim.columns) items\n",
    "for user_id in user_ratings_test.index:\n",
    "    for movie in user_ratings_test.columns:\n",
    "        # get true rating\n",
    "        true_rating = user_ratings_test.loc[user_id, movie]\n",
    "\n",
    "        # skip if true rating isnt in the test set\n",
    "        if np.isnan(true_rating):\n",
    "            continue\n",
    "        \n",
    "        # get similar items\n",
    "        sims = item_sim[movie].drop(index=movie).dropna()\n",
    "        # get top 5 most similar items\n",
    "        top_items = sims.sort_values(ascending=False).head(5)\n",
    "\n",
    "        # loop through similar items and use similar item ratings in prediction, then calculate weighted average\n",
    "        num = 0\n",
    "        denom = 0\n",
    "        for similar_movie, sim_score in top_items.items():\n",
    "            if similar_movie in user_ratings_train.columns:\n",
    "                rating = user_ratings_train.loc[user_id, similar_movie]\n",
    "                if not np.isnan(rating):\n",
    "                    num += sim_score * rating\n",
    "                    denom += abs(sim_score)\n",
    "\n",
    "        if denom > 0:\n",
    "            pred = num / denom\n",
    "            predictions.append(pred)\n",
    "            actual.append(true_rating)\n",
    "\n",
    "\n",
    "# mae\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print(\"MAE: {:.4f}\".format(mae))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
